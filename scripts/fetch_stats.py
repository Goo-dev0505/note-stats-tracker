import os
import time
import json
import csv
import sys
import pandas as pd
from datetime import datetime, timezone, timedelta
from pathlib import Path
import requests

# Windowsç’°å¢ƒã§ã®Unicodeå‡ºåŠ›å¯¾å¿œ
if sys.stdout.encoding and sys.stdout.encoding.lower() not in ("utf-8", "utf8"):
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")

# ===== è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰ =====
NOTE_COOKIE = os.environ.get("NOTE_COOKIE", "")
NOTE_USERNAME = os.environ.get("NOTE_USERNAME", "")
COOKIE_SET_DATE = os.environ.get("COOKIE_SET_DATE", "") # YYYY-MM-DDå½¢å¼
BASE_URL = "https://note.com"
DATA_DIR = Path("data")
CACHE_PATH = DATA_DIR / "v3_dates_cache.json"
JST = timezone(timedelta(hours=9))

# ===== 1. ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & èªè¨¼ãƒ­ã‚¸ãƒƒã‚¯ =====
def validate_setup():
    if not NOTE_COOKIE or not NOTE_USERNAME:
        print("ğŸš¨ NOTE_COOKIE ã¾ãŸã¯ NOTE_USERNAME ãŒæœªè¨­å®šã‚„ï¼"); sys.exit(1)
    if "=" not in NOTE_COOKIE:
        print("ğŸš¨ NOTE_COOKIE ã®å½¢å¼ãŒä¸æ­£ã‚„ï¼ˆkey=valueå½¢å¼ã«ã—ã¦ãªï¼‰"); sys.exit(1)

def verify_auth(session):
    print("ğŸ”‘ èªè¨¼ãƒã‚§ãƒƒã‚¯ä¸­...")
    url = f"{BASE_URL}/api/v1/stats/pv?filter=all&page=1&sort=pv"
    r = session.get(url, timeout=20)
    if r.status_code == 200 and "data" in r.json():
        print("âœ“ èªè¨¼OKï¼ˆstats APIã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã—ãŸï¼‰")
        return True
    else:
        print(f"ğŸš¨ èªè¨¼å¤±æ•—: HTTP {r.status_code}"); sys.exit(1)

def make_session():
    s = requests.Session()
    s.headers.update({
        "User-Agent": "Mozilla/5.0 (GitHubActions; note-fetcher)",
        "Accept": "application/json, text/plain, */*",
        "Referer": f"{BASE_URL}/{NOTE_USERNAME}",
    })
    cookies = {}
    for part in NOTE_COOKIE.split(";"):
        if "=" in part:
            k, v = part.strip().split("=", 1)
            cookies[k] = v
    s.cookies.update(cookies)
    return s

# ===== 2. ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆColabç‰ˆã®è³¢ã„æ¢ç´¢ã‚’ç¶™æ‰¿ï¼‰ =====
def deep_find_dates(obj):
    """'user'é…ä¸‹ã‚’é™¤å¤–ã—ã¦æ—¥ä»˜ã‚’æ¢ç´¢ï¼ˆColabç‰ˆãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    found = {}
    target_keys = {"published_at", "publish_at", "first_published_at", "created_at", "updated_at"}
    def walk(o, current_key=""):
        if isinstance(o, dict):
            for k, v in o.items():
                if k == "user": continue # useré…ä¸‹ã¯ç„¡è¦–
                if k in target_keys and k not in found:
                    found[k] = v
                walk(v, k)
        elif isinstance(o, list):
            for v in o[:50]: walk(v)
    walk(obj)
    # ä»£è¡¨çš„ãªã‚­ãƒ¼ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    return {
        "published_at": found.get("published_at") or found.get("publish_at") or found.get("first_published_at"),
        "created_at": found.get("created_at"),
        "updated_at": found.get("updated_at")
    }

def fetch_stats(session):
    all_notes = []
    page = 1
    total_data = {}
    while True:
        r = session.get(f"{BASE_URL}/api/v1/stats/pv", params={"filter": "all", "page": page, "sort": "pv"})
        r.raise_for_status()
        data = r.json().get("data", {})
        if page == 1:
            total_data = {k: data.get(k) for k in ["total_pv", "total_like", "total_comment"]}
        all_notes.extend(data.get("note_stats", []))
        if data.get("last_page"): break
        page += 1
    
    u = session.get(f"{BASE_URL}/api/v2/creators/{NOTE_USERNAME}")
    total_data["follower_count"] = u.json().get("data", {}).get("followerCount") if u.status_code == 200 else None
    return all_notes, total_data

# ===== 3. ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ»ä¿å­˜ï¼ˆã‚¹ãƒ—ã‚·å½¢å¼æº–æ‹ ï¼‰ =====
def main():
    validate_setup()
    session = make_session()
    verify_auth(session)
    
    print("\nğŸ“Š è¨˜äº‹ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    notes, summary = fetch_stats(session)
    df = pd.DataFrame(notes)
    
    # ã‚«ãƒ©ãƒ åã‚’ã‚¹ãƒ—ã‚·ä»•æ§˜ã«ã€Œæ“¬æ…‹ã€ã•ã›ã‚‹
    df = df.rename(columns={"name": "title", "read_count": "view", "comment_count": "comment", "like_count": "like"})
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿
    cache = {}
    if CACHE_PATH.exists():
        with open(CACHE_PATH, "r", encoding="utf-8") as f: cache = json.load(f)

    print("\nğŸ“… æŠ•ç¨¿æ—¥ã‚’v3 APIã‹ã‚‰è£œå®Œä¸­ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰...")
    updated_cache = False
    for i, row in df.iterrows():
        key = row["key"]
        if key in cache:
            dates = cache[key]
        else:
            r = session.get(f"{BASE_URL}/api/v3/notes/{key}")
            if r.status_code == 200:
                dates = deep_find_dates(r.json().get("data", {}))
                cache[key] = dates
                updated_cache = True
                time.sleep(0.1) # è² è·è»½æ¸›
            else:
                dates = {}

        for k, v in dates.items():
            df.at[i, k] = v

    if updated_cache:
        DATA_DIR.mkdir(exist_ok=True)
        with open(CACHE_PATH, "w", encoding="utf-8") as f: json.dump(cache, f, ensure_ascii=False, indent=2)

    # æ—¥ä»˜å¤‰æ›ã¨çµŒéæ—¥æ•°è¨ˆç®—
    now_jst = datetime.now(JST)
    for col in ["published_at", "created_at", "updated_at"]:
        df[col] = pd.to_datetime(df[col]).dt.tz_convert("Asia/Tokyo") if df[col].notna().any() else df[col]
    
    df["age_days"] = (now_jst - df["published_at"]).dt.days if "published_at" in df else ""

    # ğŸŒŸ ã‚¹ãƒ—ã‚·ã¨å…¨ãåŒã˜ä¸¦ã³é †ã§ä¿å­˜
    final_cols = ["key", "title", "published_at", "created_at", "updated_at", "age_days", "view", "comment", "like"]
    DATA_DIR.mkdir(exist_ok=True)
    df[final_cols].to_csv(DATA_DIR / "articles.csv", index=False, encoding="utf-8")
    
    # ã‚µãƒãƒªãƒ¼ä¿å­˜
    summary_path = DATA_DIR / "daily_summary.csv"
    summary_row = pd.DataFrame([{
        "date": now_jst.strftime("%Y-%m-%d"),
        "article_count": len(df),
        "total_pv": summary["total_pv"],
        "total_like": summary["total_like"],
        "total_comment": summary["total_comment"],
        "follower_count": summary["follower_count"]
    }])
    summary_row.to_csv(summary_path, mode='a', header=not summary_path.exists(), index=False)
    
    print(f"\n=== å®Œäº†: {len(df)}è¨˜äº‹å–å¾—å®Œäº† ===")

if __name__ == "__main__":
    main()
